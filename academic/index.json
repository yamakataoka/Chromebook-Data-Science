[{"authors":null,"categories":null,"content":"This feature can be used for publishing content such as:\n Project or software documentation Online courses Tutorials  The parent folder may be renamed, for example, to docs for project documentation or course for creating an online course.\nTo disable this feature, either delete the parent folder, or set draft = true in the front matter of all its pages.\nAfter renaming or deleting the parent folder, you may wish to update any [[menu.main]] menu links to it in the config.toml.\n","date":1536451200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1536451200,"objectID":"c3224f3a64174f08aaf31e1f1d16ffd3","permalink":"/tutorial/","publishdate":"2018-09-09T00:00:00Z","relpermalink":"/tutorial/","section":"tutorial","summary":"This feature can be used for publishing content such as:\n Project or software documentation Online courses Tutorials  The parent folder may be renamed, for example, to docs for project documentation or course for creating an online course.\nTo disable this feature, either delete the parent folder, or set draft = true in the front matter of all its pages.\nAfter renaming or deleting the parent folder, you may wish to update any [[menu.","tags":null,"title":"Overview","type":"docs"},{"authors":null,"categories":["R","survey","data analysis"],"content":" Intro \u0026amp; Background I’ve just joined the House Prices: Advanced Regression Techniques Competition, whch is a Getting Started competition.\nKaggle describes this competition as follows:\nAsk a home buyer to describe their dream house, and they probably won’t begin with the height of the basement ceiling or the proximity to an east-west railroad. But this playground competition’s dataset proves that much more influences price negotiations than the number of bedrooms or a white-picket fence.\nWith 79 explanatory variables describing (almost) every aspect of residential homes in Ames, Iowa, this competition challenges us to predict the final price of each home.\nSO, we’ll try to answer the question:\n Can you figure out how much a house will sell for?\n  The Data Accessing Data Now, we’ll download and get the data directly from the competitions data here.\nThe Ames Housing dataset was compiled by Dean De Cock for use in data science education. It’s an incredible alternative for data scientists looking for a modernized and expanded version of the often cited Boston Housing dataset.\nHere’s a brief file description;\n train.csv - the training set\n test.csv - the test set\n data_description.txt - full description of each column, originally prepared by Dean De Cock but lightly edited to match the column names used here\n sample_submission.csv - a benchmark submission from a linear regression on year and month of sale, lot square footage, and number of bedrooms\n  You can find the data dictionaries for on https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data\n Loading Data We’ll load the data and run the code below to create an object called iowa_data.\n# You\u0026#39;d read the data and store data in a tibble iowa_data \u0026lt;- read_csv(\u0026quot;data/raw_data/train.csv\u0026quot;)  ## Parsed with column specification: ## cols( ## .default = col_character(), ## Id = col_double(), ## MSSubClass = col_double(), ## LotFrontage = col_double(), ## LotArea = col_double(), ## OverallQual = col_double(), ## OverallCond = col_double(), ## YearBuilt = col_double(), ## YearRemodAdd = col_double(), ## MasVnrArea = col_double(), ## BsmtFinSF1 = col_double(), ## BsmtFinSF2 = col_double(), ## BsmtUnfSF = col_double(), ## TotalBsmtSF = col_double(), ## `1stFlrSF` = col_double(), ## `2ndFlrSF` = col_double(), ## LowQualFinSF = col_double(), ## GrLivArea = col_double(), ## BsmtFullBath = col_double(), ## BsmtHalfBath = col_double(), ## FullBath = col_double() ## # ... with 18 more columns ## ) ## See spec(...) for full column specifications. # we\u0026#39;ll make sure Condition1 is a factor \u0026amp; not a char iowa_data$Condition1 \u0026lt;- as.factor(iowa_data$Condition1)   Exploratory Analysis of Housing Prices Data # now we\u0026#39;ll summarize the iowa_data dataframe summary(iowa_data) ## Id MSSubClass MSZoning LotFrontage ## Min. : 1.0 Min. : 20.0 Length:1460 Min. : 21.00 ## 1st Qu.: 365.8 1st Qu.: 20.0 Class :character 1st Qu.: 59.00 ## Median : 730.5 Median : 50.0 Mode :character Median : 69.00 ## Mean : 730.5 Mean : 56.9 Mean : 70.05 ## 3rd Qu.:1095.2 3rd Qu.: 70.0 3rd Qu.: 80.00 ## Max. :1460.0 Max. :190.0 Max. :313.00 ## NA\u0026#39;s :259 ## LotArea Street Alley LotShape ## Min. : 1300 Length:1460 Length:1460 Length:1460 ## 1st Qu.: 7554 Class :character Class :character Class :character ## Median : 9478 Mode :character Mode :character Mode :character ## Mean : 10517 ## 3rd Qu.: 11602 ## Max. :215245 ## ## LandContour Utilities LotConfig ## Length:1460 Length:1460 Length:1460 ## Class :character Class :character Class :character ## Mode :character Mode :character Mode :character ## ## ## ## ## LandSlope Neighborhood Condition1 Condition2 ## Length:1460 Length:1460 Norm :1260 Length:1460 ## Class :character Class :character Feedr : 81 Class :character ## Mode :character Mode :character Artery : 48 Mode :character ## RRAn : 26 ## PosN : 19 ## RRAe : 11 ## (Other): 15 ## BldgType HouseStyle OverallQual OverallCond ## Length:1460 Length:1460 Min. : 1.000 Min. :1.000 ## Class :character Class :character 1st Qu.: 5.000 1st Qu.:5.000 ## Mode :character Mode :character Median : 6.000 Median :5.000 ## Mean : 6.099 Mean :5.575 ## 3rd Qu.: 7.000 3rd Qu.:6.000 ## Max. :10.000 Max. :9.000 ## ## YearBuilt YearRemodAdd RoofStyle RoofMatl ## Min. :1872 Min. :1950 Length:1460 Length:1460 ## 1st Qu.:1954 1st Qu.:1967 Class :character Class :character ## Median :1973 Median :1994 Mode :character Mode :character ## Mean :1971 Mean :1985 ## 3rd Qu.:2000 3rd Qu.:2004 ## Max. :2010 Max. :2010 ## ## Exterior1st Exterior2nd MasVnrType MasVnrArea ## Length:1460 Length:1460 Length:1460 Min. : 0.0 ## Class :character Class :character Class :character 1st Qu.: 0.0 ## Mode :character Mode :character Mode :character Median : 0.0 ## Mean : 103.7 ## 3rd Qu.: 166.0 ## Max. :1600.0 ## NA\u0026#39;s :8 ## ExterQual ExterCond Foundation ## Length:1460 Length:1460 Length:1460 ## Class :character Class :character Class :character ## Mode :character Mode :character Mode :character ## ## ## ## ## BsmtQual BsmtCond BsmtExposure ## Length:1460 Length:1460 Length:1460 ## Class :character Class :character Class :character ## Mode :character Mode :character Mode :character ## ## ## ## ## BsmtFinType1 BsmtFinSF1 BsmtFinType2 BsmtFinSF2 ## Length:1460 Min. : 0.0 Length:1460 Min. : 0.00 ## Class :character 1st Qu.: 0.0 Class :character 1st Qu.: 0.00 ## Mode :character Median : 383.5 Mode :character Median : 0.00 ## Mean : 443.6 Mean : 46.55 ## 3rd Qu.: 712.2 3rd Qu.: 0.00 ## Max. :5644.0 Max. :1474.00 ## ## BsmtUnfSF TotalBsmtSF Heating HeatingQC ## Min. : 0.0 Min. : 0.0 Length:1460 Length:1460 ## 1st Qu.: 223.0 1st Qu.: 795.8 Class :character Class :character ## Median : 477.5 Median : 991.5 Mode :character Mode :character ## Mean : 567.2 Mean :1057.4 ## 3rd Qu.: 808.0 3rd Qu.:1298.2 ## Max. :2336.0 Max. :6110.0 ## ## CentralAir Electrical 1stFlrSF 2ndFlrSF ## Length:1460 Length:1460 Min. : 334 Min. : 0 ## Class :character Class :character 1st Qu.: 882 1st Qu.: 0 ## Mode :character Mode :character Median :1087 Median : 0 ## Mean :1163 Mean : 347 ## 3rd Qu.:1391 3rd Qu.: 728 ## Max. :4692 Max. :2065 ## ## LowQualFinSF GrLivArea BsmtFullBath BsmtHalfBath ## Min. : 0.000 Min. : 334 Min. :0.0000 Min. :0.00000 ## 1st Qu.: 0.000 1st Qu.:1130 1st Qu.:0.0000 1st Qu.:0.00000 ## Median : 0.000 Median :1464 Median :0.0000 Median :0.00000 ## Mean : 5.845 Mean :1515 Mean :0.4253 Mean :0.05753 ## 3rd Qu.: 0.000 3rd Qu.:1777 3rd Qu.:1.0000 3rd Qu.:0.00000 ## Max. :572.000 Max. :5642 Max. :3.0000 Max. :2.00000 ## ## FullBath HalfBath BedroomAbvGr KitchenAbvGr ## Min. :0.000 Min. :0.0000 Min. :0.000 Min. :0.000 ## 1st Qu.:1.000 1st Qu.:0.0000 1st Qu.:2.000 1st Qu.:1.000 ## Median :2.000 Median :0.0000 Median :3.000 Median :1.000 ## Mean :1.565 Mean :0.3829 Mean :2.866 Mean :1.047 ## 3rd Qu.:2.000 3rd Qu.:1.0000 3rd Qu.:3.000 3rd Qu.:1.000 ## Max. :3.000 Max. :2.0000 Max. :8.000 Max. :3.000 ## ## KitchenQual TotRmsAbvGrd Functional Fireplaces ## Length:1460 Min. : 2.000 Length:1460 Min. :0.000 ## Class :character 1st Qu.: 5.000 Class :character 1st Qu.:0.000 ## Mode :character Median : 6.000 Mode :character Median :1.000 ## Mean : 6.518 Mean :0.613 ## 3rd Qu.: 7.000 3rd Qu.:1.000 ## Max. :14.000 Max. :3.000 ## ## FireplaceQu GarageType GarageYrBlt GarageFinish ## Length:1460 Length:1460 Min. :1900 Length:1460 ## Class :character Class :character 1st Qu.:1961 Class :character ## Mode :character Mode :character Median :1980 Mode :character ## Mean :1979 ## 3rd Qu.:2002 ## Max. :2010 ## NA\u0026#39;s :81 ## GarageCars GarageArea GarageQual GarageCond ## Min. :0.000 Min. : 0.0 Length:1460 Length:1460 ## 1st Qu.:1.000 1st Qu.: 334.5 Class :character Class :character ## Median :2.000 Median : 480.0 Mode :character Mode :character ## Mean :1.767 Mean : 473.0 ## 3rd Qu.:2.000 3rd Qu.: 576.0 ## Max. :4.000 Max. :1418.0 ## ## PavedDrive WoodDeckSF OpenPorchSF EnclosedPorch ## Length:1460 Min. : 0.00 Min. : 0.00 Min. : 0.00 ## Class :character 1st Qu.: 0.00 1st Qu.: 0.00 1st Qu.: 0.00 ## Mode :character Median : 0.00 Median : 25.00 Median : 0.00 ## Mean : 94.24 Mean : 46.66 Mean : 21.95 ## 3rd Qu.:168.00 3rd Qu.: 68.00 3rd Qu.: 0.00 ## Max. :857.00 Max. :547.00 Max. :552.00 ## ## 3SsnPorch ScreenPorch PoolArea PoolQC ## Min. : 0.00 Min. : 0.00 Min. : 0.000 Length:1460 ## 1st Qu.: 0.00 1st Qu.: 0.00 1st Qu.: 0.000 Class :character ## Median : 0.00 Median : 0.00 Median : 0.000 Mode :character ## Mean : 3.41 Mean : 15.06 Mean : 2.759 ## 3rd Qu.: 0.00 3rd Qu.: 0.00 3rd Qu.: 0.000 ## Max. :508.00 Max. :480.00 Max. :738.000 ## ## Fence MiscFeature MiscVal MoSold ## Length:1460 Length:1460 Min. : 0.00 Min. : 1.000 ## Class :character Class :character 1st Qu.: 0.00 1st Qu.: 5.000 ## Mode :character Mode :character Median : 0.00 Median : 6.000 ## Mean : 43.49 Mean : 6.322 ## 3rd Qu.: 0.00 3rd Qu.: 8.000 ## Max. :15500.00 Max. :12.000 ## ## YrSold SaleType SaleCondition SalePrice ## Min. :2006 Length:1460 Length:1460 Min. : 34900 ## 1st Qu.:2007 Class :character Class :character 1st Qu.:129975 ## Median :2008 Mode :character Mode :character Median :163000 ## Mean :2008 Mean :180921 ## 3rd Qu.:2009 3rd Qu.:214000 ## Max. :2010 Max. :755000 ##  Each little chunk of output (e.g. “X1”, “Suburb”, “Address”, “Rooms”) tell us about a specific column in our dataframe.\nIf the column is numeric, though, it will list information about the mean, median, 25th and 75th quartiles, minimum and maximum.\nThe median year in which the houses in this dataset were built is 1973 (YearBuilt). In addtion, we’ll find that the maximum number or rooms are 14 (TotRmsAbvGrd).\n Prediction Data Analysis Data Splitting We’ll take our dataset and split it into a training set and a tuning set.\n## get Index for training set set.seed(123) trainIndex \u0026lt;- createDataPartition(iowa_data$Id, p = .7, list = FALSE, times = 1) ## split into training and tuning set iowa_train \u0026lt;- iowa_data %\u0026gt;% slice(trainIndex) iowa_tune \u0026lt;- iowa_data %\u0026gt;% slice(-trainIndex)  Decision Tree analysis We can then fit a new model using our training data and test it using our testing data.\nWe’ll be predicting the SalePrice variable. And we start with a narrower set of numeric variables and fit a model that can predict your target variable using the following predictors;\n LotArea\n YearBuilt\n Condition1 (how close to the main road the house is)\n FullBath\n BedroomAbvGr\n TotRmsAbvGrd\n  We’re going to use the rpart() function from the rpart package to build our decision tree using the prediction target (SalePrice) and predictors (set of numeric variables).\n# build a model to predict housing prices in Iowa using our training set fit \u0026lt;- rpart(SalePrice ~ TotRmsAbvGrd + FullBath + LotArea + Condition1 + YearBuilt + BedroomAbvGr, data = iowa_train) # get the mean average error for our model mae(model = fit, data = iowa_tune) ## [1] 37534.09 Then, we just started with one called Mean Absolute Error (also called MAE) for summarizing model quality.\nThe prediction error for each house is:\n \\(error=actual−predicted\\)\n With the MAE metric, we take the absolute value of each error. This converts each error to a positive number. We then take the average of those absolute errors. This is our measure of model quality.\nWe can get the MAE for our model using the mae() function, from the modelr package. The mae() function takes in a model and the dataset to test it against.\nOn average, our predictions are off by about 37534.09 dollars.\nNow, we built prediction model, so we can actually look at the tree it has built.\n# plot our regression tree plot(fit, uniform=TRUE) # add text labels \u0026amp; make them 60% as big as they are by default text(fit, cex=.6) We can now use our fitted model to predict the prices of some houses, using the predict() function for our tuning set.\nprint(\u0026quot;Making predictions for the following 5 houses:\u0026quot;) ## [1] \u0026quot;Making predictions for the following 5 houses:\u0026quot; print(head(iowa_tune)) ## # A tibble: 6 x 81 ## Id MSSubClass MSZoning LotFrontage LotArea Street Alley LotShape ## \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; ## 1 2 20 RL 80 9600 Pave \u0026lt;NA\u0026gt; Reg ## 2 4 70 RL 60 9550 Pave \u0026lt;NA\u0026gt; IR1 ## 3 5 60 RL 84 14260 Pave \u0026lt;NA\u0026gt; IR1 ## 4 6 50 RL 85 14115 Pave \u0026lt;NA\u0026gt; IR1 ## 5 7 20 RL 75 10084 Pave \u0026lt;NA\u0026gt; Reg ## 6 10 190 RL 50 7420 Pave \u0026lt;NA\u0026gt; Reg ## # ... with 73 more variables: LandContour \u0026lt;chr\u0026gt;, Utilities \u0026lt;chr\u0026gt;, ## # LotConfig \u0026lt;chr\u0026gt;, LandSlope \u0026lt;chr\u0026gt;, Neighborhood \u0026lt;chr\u0026gt;, ## # Condition1 \u0026lt;fct\u0026gt;, Condition2 \u0026lt;chr\u0026gt;, BldgType \u0026lt;chr\u0026gt;, HouseStyle \u0026lt;chr\u0026gt;, ## # OverallQual \u0026lt;dbl\u0026gt;, OverallCond \u0026lt;dbl\u0026gt;, YearBuilt \u0026lt;dbl\u0026gt;, ## # YearRemodAdd \u0026lt;dbl\u0026gt;, RoofStyle \u0026lt;chr\u0026gt;, RoofMatl \u0026lt;chr\u0026gt;, ## # Exterior1st \u0026lt;chr\u0026gt;, Exterior2nd \u0026lt;chr\u0026gt;, MasVnrType \u0026lt;chr\u0026gt;, ## # MasVnrArea \u0026lt;dbl\u0026gt;, ExterQual \u0026lt;chr\u0026gt;, ExterCond \u0026lt;chr\u0026gt;, Foundation \u0026lt;chr\u0026gt;, ## # BsmtQual \u0026lt;chr\u0026gt;, BsmtCond \u0026lt;chr\u0026gt;, BsmtExposure \u0026lt;chr\u0026gt;, ## # BsmtFinType1 \u0026lt;chr\u0026gt;, BsmtFinSF1 \u0026lt;dbl\u0026gt;, BsmtFinType2 \u0026lt;chr\u0026gt;, ## # BsmtFinSF2 \u0026lt;dbl\u0026gt;, BsmtUnfSF \u0026lt;dbl\u0026gt;, TotalBsmtSF \u0026lt;dbl\u0026gt;, Heating \u0026lt;chr\u0026gt;, ## # HeatingQC \u0026lt;chr\u0026gt;, CentralAir \u0026lt;chr\u0026gt;, Electrical \u0026lt;chr\u0026gt;, `1stFlrSF` \u0026lt;dbl\u0026gt;, ## # `2ndFlrSF` \u0026lt;dbl\u0026gt;, LowQualFinSF \u0026lt;dbl\u0026gt;, GrLivArea \u0026lt;dbl\u0026gt;, ## # BsmtFullBath \u0026lt;dbl\u0026gt;, BsmtHalfBath \u0026lt;dbl\u0026gt;, FullBath \u0026lt;dbl\u0026gt;, ## # HalfBath \u0026lt;dbl\u0026gt;, BedroomAbvGr \u0026lt;dbl\u0026gt;, KitchenAbvGr \u0026lt;dbl\u0026gt;, ## # KitchenQual \u0026lt;chr\u0026gt;, TotRmsAbvGrd \u0026lt;dbl\u0026gt;, Functional \u0026lt;chr\u0026gt;, ## # Fireplaces \u0026lt;dbl\u0026gt;, FireplaceQu \u0026lt;chr\u0026gt;, GarageType \u0026lt;chr\u0026gt;, ## # GarageYrBlt \u0026lt;dbl\u0026gt;, GarageFinish \u0026lt;chr\u0026gt;, GarageCars \u0026lt;dbl\u0026gt;, ## # GarageArea \u0026lt;dbl\u0026gt;, GarageQual \u0026lt;chr\u0026gt;, GarageCond \u0026lt;chr\u0026gt;, ## # PavedDrive \u0026lt;chr\u0026gt;, WoodDeckSF \u0026lt;dbl\u0026gt;, OpenPorchSF \u0026lt;dbl\u0026gt;, ## # EnclosedPorch \u0026lt;dbl\u0026gt;, `3SsnPorch` \u0026lt;dbl\u0026gt;, ScreenPorch \u0026lt;dbl\u0026gt;, ## # PoolArea \u0026lt;dbl\u0026gt;, PoolQC \u0026lt;chr\u0026gt;, Fence \u0026lt;chr\u0026gt;, MiscFeature \u0026lt;chr\u0026gt;, ## # MiscVal \u0026lt;dbl\u0026gt;, MoSold \u0026lt;dbl\u0026gt;, YrSold \u0026lt;dbl\u0026gt;, SaleType \u0026lt;chr\u0026gt;, ## # SaleCondition \u0026lt;chr\u0026gt;, SalePrice \u0026lt;dbl\u0026gt; print(\u0026quot;The predictions are\u0026quot;) ## [1] \u0026quot;The predictions are\u0026quot; print(predict(fit, head(iowa_tune))) ## 1 2 3 4 5 6 ## 150232.8 150232.8 259061.7 340455.9 200815.1 122309.3 print(\u0026quot;Actual price\u0026quot;) ## [1] \u0026quot;Actual price\u0026quot; print(head(iowa_tune$SalePrice)) ## [1] 181500 140000 250000 143000 307000 118000 So, as you can above, the first house we predicted cost 181,500 dollars and you predicted it would cost 150,232.8 dollars the error is 31,267.2 dollars.\nThen now, we are setting the tree depth with the maxdepth argument to control overfitting vs underfitting.\nWe can use a utility function to help compare MAE scores from different values for maxdepth:\n# a function to get the maximum average error for a given max depth. You should pass in # the target as the name of the target column and the predictors as vector where # each item in the vector is the name of the column get_mae \u0026lt;- function(maxdepth, target, predictors, training_data, tuning_data){ # turn the predictors \u0026amp; target into a formula to pass to rpart() predictors \u0026lt;- paste(predictors, collapse=\u0026quot;+\u0026quot;) formula \u0026lt;- as.formula(paste(target,\u0026quot;~\u0026quot;,predictors,sep = \u0026quot;\u0026quot;)) # build our model model \u0026lt;- rpart(formula, data = training_data, control = rpart.control(maxdepth = maxdepth)) # get the mae mae \u0026lt;- mae(model, tuning_data) return(mae) } We can use a for-loop to compare the accuracy of models built with different values for maxdepth. In this case, the lowest MAE is actually 5.\n# target \u0026amp; predictors to feed into our formula target \u0026lt;- \u0026quot;SalePrice\u0026quot; predictors \u0026lt;- c(\u0026quot;TotRmsAbvGrd\u0026quot;, \u0026quot;FullBath\u0026quot;, \u0026quot;LotArea\u0026quot;, \u0026quot;Condition1\u0026quot;, \u0026quot;YearBuilt\u0026quot;, \u0026quot;BedroomAbvGr\u0026quot;) # get the MAE for maxdepths between 1 \u0026amp; 10 for(i in 1:10){ mae \u0026lt;- get_mae(maxdepth = i, target = target, predictors = predictors, training_data = iowa_train, tuning_data = iowa_tune) print(glue::glue(\u0026quot;Maxdepth: \u0026quot;,i,\u0026quot;\\t MAE: \u0026quot;,mae)) } ## Maxdepth: 1 MAE: 46982.6810339195 ## Maxdepth: 2 MAE: 41968.2267110074 ## Maxdepth: 3 MAE: 39012.1922817192 ## Maxdepth: 4 MAE: 38863.924322096 ## Maxdepth: 5 MAE: 37534.0937255204 ## Maxdepth: 6 MAE: 37534.0937255204 ## Maxdepth: 7 MAE: 37534.0937255204 ## Maxdepth: 8 MAE: 37534.0937255204 ## Maxdepth: 9 MAE: 37534.0937255204 ## Maxdepth: 10 MAE: 37534.0937255204 37,534.09 is the lowest mean average error for this dataset, which is given this dataset and our current stopping condition, 6 is the maximum number of nodes.\n Random Forests analysis # fit a random forest model to our training set fitRandomForest \u0026lt;- randomForest(SalePrice ~ TotRmsAbvGrd + FullBath + LotArea + Condition1 + YearBuilt + BedroomAbvGr, data = iowa_train) # get the mean average error for our new model, based on our tuning set mae(model = fitRandomForest, data = iowa_tune) ## [1] 30894.18 On average, this predictions are off by around 30,894.18 dollars. This is a big improvement over our previous best decision tree.\n  Conclusion We analyzed and tried to answer the question:\n Can you figure out how much a house will sell for?\n Then, I’ve submitted above prediction values for the House Prices: Advanced Regression Techniques Competition. As a result, I’ve ranked at 3624th.\n ","date":1546214400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546214400,"objectID":"d352d2c6a0cf7babc429c632dd5a3e27","permalink":"/project/ames_housing_prices_project/ames-housing-prices/","publishdate":"2018-12-31T00:00:00Z","relpermalink":"/project/ames_housing_prices_project/ames-housing-prices/","section":"project","summary":"Prediction of Ames Housing Prices Data","tags":["R","dataviz","analysis","machine-learning"],"title":"Ames Housing Prices Project","type":"project"},{"authors":null,"categories":["R","survey","data analysis"],"content":" Intro \u0026amp; Background I’ve just finished Final Project of Data Analysis course on leanpub.\nCompleted Data Analysis from @leanpub Completed 9/11 from #CBDS #DataScience pic.twitter.com/ZYIthtiAGP — Yamato Kataoka (@_yamatt) December 24, 2018   This project has been generated to practice everything I have learned in this course set.\nWe’ll be interested in some sort of questions like:\n Does women or men spend more time with their children?\n  Do younger parents spend more time with their children?\n  Do richer people spend more time with their children compared to poorer people?\n  Do married couples spend more time with their children compared to single parents?\n  Do full-time workers spend more time with their children compared to part-time workers?\n  How do different income groups spend time doing each activity?\n  Data The American Time Use Survey (ATUS) is a time-use survey of Americans, which is sponsored by the Bureau of Labor Statistics (BLS) and conducted by the U.S. Census Bureau. Respondents of the survey are asked to keep a diary for one day carefully recording the amount of time they spend on various activities including working, leisure, childcare, and household activities.\nIncluded in the data are main demographic variables such as respondents’ age, sex, race, marital status, and education. The data also includes detailed income and employment information for each respondent. While there are some slight changes to the survey each year, the main questions asked stay the same. You can find data dictionaries (also called codebooks) at https://www.bls.gov/tus/atuscpscodebk16.pdf for the CPS data and at https://www.bls.gov/tus/atusintcodebk16.pdf for the rest of the variables.\nImporting Data First we’ll have to upload the two .dat files (atuscps_2016.dat and atussum_2016.dat) into RStudio Cloud after download from https://www.bls.gov/tus/#data and create an object called atus.all.:\nlibrary(janitor) library(ggplot2) library(dplyr) library(lubridate) library(zoo) library(forcats) library(ggthemes) library(knitr) library(tidyr) # Read a file in table format and creates a data frame from it atus.cps \u0026lt;- read.delim(\u0026#39;data/raw_data/atuscps_2016.dat\u0026#39;, sep=\u0026quot;,\u0026quot;) atus.sum \u0026lt;- read.delim(\u0026#39;data/raw_data/atussum_2016.dat\u0026#39;, sep=\u0026quot;,\u0026quot;) # We can create a table including these two dataset # separeted by each respondent(TUCASEID) atus.all \u0026lt;- atus.sum %\u0026gt;% left_join(atus.cps %\u0026gt;% filter(TULINENO==1), by = c(\u0026quot;TUCASEID\u0026quot;))   Exploratory Data Analysis https://www.bls.gov/tus/lexiconwex2016.pdf lists all the activity codes. All activities start with t and then a 6-digit number that combines the major category, the 2nd tier, and the 3rd tier of the activity.\nWe’ll figure out How much time, on average, does a person in the sample spend on “Socializing and communicating with others”?. According to https://www.bls.gov/tus/lexiconwex2016.pdf, We’ll find the variable, t120101, associated with “Socializing and communicating with others.”\n## “Socializing and communicating with others” is 120101 from https://www.bls.gov/tus/lexiconwex2016.pdf mean(atus.all$t120101) ## [1] 38.06481 We’ll also find the activity code that is associated with “Caring For \u0026amp; Helping HH Children” to show overview of childcare. I created a column in the data frame atus.all called CHILDCARE that is the sum of all the columns that start with t0301.\natus.all \u0026lt;- atus.all %\u0026gt;% # We can culculate the sum of all the columns that start with `t0301` # which is related childcare. mutate(CHILDCARE = rowSums(.[, grep(\u0026#39;t0301\u0026#39;, colnames(.))])) I’m wiriting code in ggplot2 to plot the density function of the variable CHILDCARE.\nggplot(atus.all) + geom_density(aes(atus.all$CHILDCARE)) Almost all people spend around 30 minites for caring child.\n Analysis Approach Inferential Data Analysis We are going to answer whether women or men spend more time with their children. Just start by grouping individuals by their gender and calculate the average time men and women spend with their children.\natus.all %\u0026gt;% # Grouping by TESEX which is refered as respondent\u0026#39;s sex group_by(TESEX) %\u0026gt;% summarize(., average_time = mean(CHILDCARE, na.rm = T)) ## # A tibble: 2 x 2 ## TESEX average_time ## \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; ## 1 1 19.0 ## 2 2 33.2 We can see that women (2), on average, spend around 33 minutes more with their children than men(1).\nWe’ll use the table() function to look at the variable TRDPFTPT which shows whether the person works full time or part time. You will notice that the variable also takes the value -1. This is probably due to non-response or other data collection reasons. Replace these values with NA in your data so they don’t affect your analysis.\n## replace -1 in the variable TRDPFTPT with NA. atus.all$TRDPFTPT[atus.all$TRDPFTPT==-1] \u0026lt;- \u0026quot;NA\u0026quot; We’ll find 4119 NAs in the dataset.\nNow, we are going to explore what factors affect time spent with children. We are going to answer questions like:\n Do younger parents spend more time with their children?\n  Do richer people spend more time with their children compared to poorer people?\n  Do married couples spend more time with their children compared to single parents?\n  Do full-time workers spend more time with their children compared to part-time workers?\n We’ll wrangle the data for each questions first.\n# You\u0026#39;d label from 0 to 95 by 5 for each person labs \u0026lt;- c(paste(seq(0, 95, by = 5), seq(0 + 5 - 1, 100 - 1, by = 5), sep = \u0026quot;-\u0026quot;), paste(100, \u0026quot;+\u0026quot;, sep = \u0026quot;\u0026quot;)) # Mutated AGEGROUP colume by labs atus.all$AGEGROUP \u0026lt;- cut(atus.all$TEAGE, breaks = c(seq(0, 100, by = 5), Inf), labels = labs, right = FALSE) # Limited data to those who have at least one child (18 or younger) in the household # The variable for the number of children (18 or younger) in the household is TRCHILDNUM. atus.all.child \u0026lt;- atus.all %\u0026gt;% filter(.$TRCHILDNUM \u0026gt; 0)  Now, we’ll answer each question.\n## Do younger parents spend more time with their children? AGEGROUP.CHILDCARE \u0026lt;- atus.all.child %\u0026gt;% group_by(AGEGROUP) %\u0026gt;% summarize(., average_time = mean(CHILDCARE, na.rm = T)) # You\u0026#39;d show average time for childcare by age group ggplot(AGEGROUP.CHILDCARE, aes(x = AGEGROUP.CHILDCARE$AGEGROUP, y = AGEGROUP.CHILDCARE$average_time)) + geom_col() ## Do richer people spend more time with their children compared to poorer people? HEFAMINC.CHILDCARE \u0026lt;- atus.all.child %\u0026gt;% # HEFAMINC is the variable which is Family Income # 1: Less than $5,000 # 2: $5,000 to $7,499 # 3: $7,500 to $9,999 # 4: $10,000 to $12,499 # 5: $12,500 to $14,999 # 6: $15,000 to $19,999 # 7: $20,000 to $24,999 # 8: $25,000 to $29,999 # 9: $30,000 to $34,999 # 10: $35,000 to $39,999 # 11: $40,000 to $49,999 # 12: $50,000 to $59,999 # 13: $60,000 to $74,999 # 14: $75,000 to $99,999 # 15: $100,000 to $149,999 # 16: $150,000 and over group_by(HEFAMINC) %\u0026gt;% summarize(., average_time = mean(CHILDCARE, na.rm = T)) ggplot(HEFAMINC.CHILDCARE, aes(x = HEFAMINC.CHILDCARE$HEFAMINC, y = HEFAMINC.CHILDCARE$average_time)) + geom_col() + scale_x_continuous(breaks = HEFAMINC.CHILDCARE$HEFAMINC)  ## Do married couples spend more time with their children compared to single parents? PEMARITL.CHILDCARE \u0026lt;- atus.all.child %\u0026gt;% # PEMARITL refers a question, are you now married, widowed, divorced, separated, or never married? # 1: Married - spouse present # 2: Married - spouse absent # 3: Widowed # 4: Divorced # 5: Separated # 6: Never married group_by(PEMARITL) %\u0026gt;% summarize(., average_time = mean(CHILDCARE, na.rm = T)) ggplot(PEMARITL.CHILDCARE, aes(x = PEMARITL.CHILDCARE$PEMARITL, y = PEMARITL.CHILDCARE$average_time)) + geom_col() + scale_x_continuous(breaks = PEMARITL.CHILDCARE$PEMARITL)  ## Do full-time workers spend more time with their children compared to part-time workers? TRDPFTPT.CHILDCARE \u0026lt;- atus.all.child %\u0026gt;% # Again TRDPFTPT is Full time (1) or part time (2) employment status of respondent group_by(TRDPFTPT) %\u0026gt;% summarize(., average_time = mean(CHILDCARE, na.rm = T)) ggplot(TRDPFTPT.CHILDCARE, aes(x = TRDPFTPT.CHILDCARE$TRDPFTPT, y = TRDPFTPT.CHILDCARE$average_time)) + geom_col() In the analysis above, we looked at bilateral (two-way) relationships. I have learned in this course, however, that other confounding variables can be a source of bias in my analysis. So it’s much better to look at the relationship of all relevant variables associated with time spent with children together. We’ll run a linear regression of marital status, age, sex, number of children (18 or younger), earnings, and full-time versus part-time status.\nreg_model \u0026lt;- lm(CHILDCARE ~ PEMARITL + TEAGE + TESEX + TRCHILDNUM + HEFAMINC + TRDPFTPT, data = atus.all.child) summary(reg_model) ## ## Call: ## lm(formula = CHILDCARE ~ PEMARITL + TEAGE + TESEX + TRCHILDNUM + ## HEFAMINC + TRDPFTPT, data = atus.all.child) ## ## Residuals: ## Min 1Q Median 3Q Max ## -142.18 -57.55 -31.57 24.01 815.46 ## ## Coefficients: ## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 69.2225 10.7976 6.411 1.60e-10 *** ## PEMARITL -12.2342 0.8308 -14.726 \u0026lt; 2e-16 *** ## TEAGE -1.0881 0.1355 -8.032 1.23e-15 *** ## TESEX 33.8984 3.1078 10.907 \u0026lt; 2e-16 *** ## TRCHILDNUM 9.0004 1.5500 5.807 6.83e-09 *** ## HEFAMINC -0.4417 0.4038 -1.094 0.274 ## TRDPFTPT2 -2.4322 4.3800 -0.555 0.579 ## TRDPFTPTNA 16.4812 3.6774 4.482 7.60e-06 *** ## --- ## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1 ## ## Residual standard error: 96.59 on 4305 degrees of freedom ## Multiple R-squared: 0.08907, Adjusted R-squared: 0.08759 ## F-statistic: 60.13 on 7 and 4305 DF, p-value: \u0026lt; 2.2e-16 In the regression, the coefficient on the variable age means how much time spent with children changes if age increases by 1. Based on our results, the difference in minutes spent with children between two people with 10 years of age difference is 10 minites.\nWe are going to see whether time spent on different activities varies by age. However, we will only consider activities at the major category levels. There are 18 major categories in the data including personal care, household activities, caring for \u0026amp; helping household members, etc. Because each activity column in the data is at the 3rd tier, we will need to start by suming columns at the activity major categories levels.\n# Saved the resulting data frame as df.wide. atus.wide \u0026lt;- atus.all %\u0026gt;% mutate(act01 = rowSums(.[, grep(\u0026#39;t01\u0026#39;, colnames(.))]), act02 = rowSums(.[, grep(\u0026#39;t02\u0026#39;, colnames(.))]), act03 = rowSums(.[, grep(\u0026#39;t03\u0026#39;, colnames(.))]), act04 = rowSums(.[, grep(\u0026#39;t04\u0026#39;, colnames(.))]), act05 = rowSums(.[, grep(\u0026#39;t05\u0026#39;, colnames(.))]), act06 = rowSums(.[, grep(\u0026#39;t06\u0026#39;, colnames(.))]), act07 = rowSums(.[, grep(\u0026#39;t07\u0026#39;, colnames(.))]), act08 = rowSums(.[, grep(\u0026#39;t08\u0026#39;, colnames(.))]), act09 = rowSums(.[, grep(\u0026#39;t09\u0026#39;, colnames(.))]), act10 = rowSums(.[, grep(\u0026#39;t10\u0026#39;, colnames(.))]), act11 = rowSums(.[, grep(\u0026#39;t11\u0026#39;, colnames(.))]), act12 = rowSums(.[, grep(\u0026#39;t12\u0026#39;, colnames(.))]), act13 = rowSums(.[, grep(\u0026#39;t13\u0026#39;, colnames(.))]), act14 = rowSums(.[, grep(\u0026#39;t14\u0026#39;, colnames(.))]), act15 = rowSums(.[, grep(\u0026#39;t15\u0026#39;, colnames(.))]), act16 = rowSums(.[, grep(\u0026#39;t16\u0026#39;, colnames(.))]), # act17 = , there is no category 17 in the data act18 = rowSums(.[, grep(\u0026#39;t18\u0026#39;, colnames(.))])) %\u0026gt;% select(TUCASEID, TEAGE, HEFAMINC, starts_with(\u0026quot;act\u0026quot;)) I’ll convert the data from wide to long and saved the data frame as df.long.\natus.long \u0026lt;- atus.wide %\u0026gt;% # use code to convert the wide format to long. gather(key=\u0026quot;ACTIVITY\u0026quot;, value=\u0026quot;MINS\u0026quot;, act01:act18) Calculating the average time for each age group and call it AVGMINS. In ggplot2, plot AVGMINS against TEAGE for each category (multiple panels).Label each panel in your graph with the appropriate activity name.\nactivity_names \u0026lt;- c( \u0026quot;act01\u0026quot; = \u0026quot;Personal Care\u0026quot;, \u0026quot;act02\u0026quot; = \u0026quot;Household Activities\u0026quot;, \u0026quot;act03\u0026quot; = \u0026quot;Caring For \u0026amp; Helping Household Members\u0026quot;, \u0026quot;act04\u0026quot; = \u0026quot;Caring For \u0026amp; Helping NonHH Members\u0026quot;, \u0026quot;act05\u0026quot; = \u0026quot;Work \u0026amp; Work-Related Activities\u0026quot;, \u0026quot;act06\u0026quot; = \u0026quot;Education\u0026quot;, \u0026quot;act07\u0026quot; = \u0026quot;Consumer Purchases\u0026quot;, \u0026quot;act08\u0026quot; = \u0026quot;Professional \u0026amp; Personal Care Services\u0026quot;, \u0026quot;act09\u0026quot; = \u0026quot;Household Services\u0026quot;, \u0026quot;act10\u0026quot; = \u0026quot;Government Services \u0026amp; Civic Obligations\u0026quot;, \u0026quot;act11\u0026quot; = \u0026quot;Eating and Drinking\u0026quot;, \u0026quot;act12\u0026quot; = \u0026quot;Socializing, Relaxing, and Leisure\u0026quot;, \u0026quot;act13\u0026quot; = \u0026quot;Sports, Exercise, and Recreation\u0026quot;, \u0026quot;act14\u0026quot; = \u0026quot;Religious and Spiritual Activities\u0026quot;, \u0026quot;act15\u0026quot; = \u0026quot;Volunteer Activities\u0026quot;, \u0026quot;act16\u0026quot; = \u0026quot;Telephone Calls\u0026quot;, \u0026quot;act18\u0026quot; = \u0026quot;Traveling\u0026quot; ) atus.long %\u0026gt;% group_by(ACTIVITY, TEAGE) %\u0026gt;% summarise(AVGMINS = mean(MINS)) %\u0026gt;% ggplot(data = .) + geom_point(mapping = aes(x = TEAGE, y = AVGMINS)) + facet_wrap(~ACTIVITY, labeller = as_labeller(activity_names)) As you can see, the average time spent on Personal Care, Work \u0026amp; Work-Related Activities and Socializing, Relaxing, and Leisure varyed by age. In addtion, middle aged people work the most compared to younger and older people based on the activity category 5 (Work \u0026amp; Work-Related Activities) on the graph. About the activity category 12 (Socializing, Relaxing, and Leisure), Older people spend more time socializing.\n  Data Visualization Finally, we are going to create a graph that shows how different income groups spend time doing each activity. The graph is based on Henrik Lindberg’s data visualization posted here. The only difference is that we are only looking at the 18 major activity categories. We’ll use the long data that you created in the previous section and make the graph as close as possible to the graph by Henrik Lindberg.\n## wrangle the data set atus.long$income_pref \u0026lt;- factor(cut(atus.long$HEFAMINC, breaks = c(0,3,6,8,11,13,14,15,Inf), labels = c(\u0026quot;$0-10k\u0026quot;, \u0026quot;$10k-20k\u0026quot;, \u0026quot;$20k-30k\u0026quot;, \u0026quot;$30k-50k\u0026quot;, \u0026quot;$50k-75k\u0026quot;, \u0026quot;$75k-100k\u0026quot;,\u0026quot;$100k-150k\u0026quot;, \u0026quot;$150k+\u0026quot;), ordered_result = T)) df \u0026lt;- atus.long %\u0026gt;% group_by(ACTIVITY, income_pref) %\u0026gt;% summarise(AVGMINS = mean(MINS)) df1 \u0026lt;- aggregate(df$AVGMINS, by=list(ACTIVITY=df$ACTIVITY), FUN=sum) df2 \u0026lt;- df[grep(c(\u0026quot;10k|30k\u0026quot;), df$income_pref),] df2 \u0026lt;- aggregate(df2$AVGMINS, by=list(ACTIVITY=df2$ACTIVITY), FUN=sum) x = df2$x/df1$x df2$PERCENT \u0026lt;- c(x) df2 \u0026lt;- df2 %\u0026gt;% arrange(desc(PERCENT)) p \u0026lt;- atus.long %\u0026gt;% group_by(ACTIVITY, income_pref) %\u0026gt;% summarise(AVGMINS = mean(MINS)) %\u0026gt;% ggplot() + ## specify you want to generate a bar chart geom_bar(aes(x = ACTIVITY, y = AVGMINS, fill = income_pref), stat = \u0026#39;identity\u0026#39;, position = position_fill(reverse = TRUE)) + ## flip coordinates to make horizontal box plot coord_flip() + ## change the colors of the bars scale_fill_manual(values = c(\u0026quot;royalblue4\u0026quot;,\u0026quot;royalblue3\u0026quot;, \u0026quot;deepskyblue3\u0026quot;, \u0026quot;deepskyblue2\u0026quot;,\u0026quot;goldenrod\u0026quot;,\u0026quot;darkgoldenrod3\u0026quot;, \u0026quot;darkgoldenrod\u0026quot;, \u0026quot;darkgoldenrod4\u0026quot;)) + ## change the scale/labels of the actvity variable (x-axis) scale_x_discrete(limits = fct_rev(df2$ACTIVITY), labels = activity_names) + ## change the title, subtitle, and caption labs(title=\u0026quot;Income distributions in Americans\u0026#39; pastimes\u0026quot;, subtitle=\u0026quot;This chart shows the income distribution of adult\\n participans in different major spastimes. Blue groups\\n earn less then the median household income\\n ($50,000/year) and brown groups earn more.\\n The bottom legend show the total population and\\n the limits that define each group. Activities are\\n odered by the percentage of above-median participation\\n, meaning that activities that more people with low\\n income do are at the bottom.\u0026quot;, caption=\u0026quot;Source: American Time Use Survey\u0026quot;) + ## change the theme (use ggthemes) theme_void() + guides(fill=guide_legend(title=NULL)) + ## fine tune the theme theme(axis.text = element_text(size = 10, hjust = 1), title = element_text(size = 16, family = \u0026quot;Times\u0026quot;), plot.subtitle = element_text(size = 12, family = \u0026quot;Times\u0026quot;), legend.position = \u0026#39;bottom\u0026#39;, legend.text = element_text(size=7), legend.title.align = 1, plot.caption = element_text(size = 10, face = \u0026quot;italic\u0026quot;), panel.grid.major = element_blank(), panel.grid.minor = element_blank(), axis.text.x = element_blank()) p A few observations:\n Blue groups (less than the median household income　($50,000/year)) spent more time on three categories (Socializing, Relaxing, and Leisure, Religious and Spiritual Activities and Telephone Calls).\n People with high income work harder than ones with low\n   Conclusion We analyzed and answered some questions as the final project on Data Analysis course to try to:\n Translate a general question into a data science question\n Identify the type of data science question we are answering\n Use data visualization and linear models to answer descriptive, exploratory,\n inferential and predictive questions\n Implement our answers in code.\n  I was fascinated by entire leanpub courses offered by faculty members in the Johns Hopkins Department of Biostatistics, Johns Hopkins Bloomberg School of Public Health. Please check out the course website.\n ","date":1546041600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546041600,"objectID":"2f2ba4ab531040e84c2ca3de6e721c58","permalink":"/project/atus_survey/atus-survey-data/","publishdate":"2018-12-29T00:00:00Z","relpermalink":"/project/atus_survey/atus-survey-data/","section":"project","summary":"Analysis of 2016 American Time Use Survey (ATUS) Data","tags":["R","dataviz","analysis"],"title":"ATUS Survey Data","type":"project"},{"authors":null,"categories":["R"],"content":" Welcome I’m Yamato Kataoka! I’ve recently completed the Chromebook Data Science Course Set on Leanpub.\nI’m interested in working with data and answering interesting questions.\n ","date":1546041600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546041600,"objectID":"10065deaa3098b0da91b78b48d0efc71","permalink":"/post/2015-07-23-r-rmarkdown/","publishdate":"2018-12-29T00:00:00Z","relpermalink":"/post/2015-07-23-r-rmarkdown/","section":"post","summary":" Welcome I’m Yamato Kataoka! I’ve recently completed the Chromebook Data Science Course Set on Leanpub.\nI’m interested in working with data and answering interesting questions.\n ","tags":["Welcome"],"title":"Welcome!","type":"post"},{"authors":null,"categories":null,"content":" In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 \u0026hellip;\nTip 2 \u0026hellip;\n","date":1536451200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1536451200,"objectID":"6a451186c775f5f0adb3a0416d0cb711","permalink":"/tutorial/example/","publishdate":"2018-09-09T00:00:00Z","relpermalink":"/tutorial/example/","section":"tutorial","summary":"In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 \u0026hellip;\nTip 2 \u0026hellip;","tags":null,"title":"Example Page","type":"docs"},{"authors":[],"categories":null,"content":"Click on the Slides button above to view the built-in slides feature.\n Slides can be added in a few ways:\n Create slides using Academic\u0026rsquo;s Slides feature and link using url_slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes.  Further talk details can easily be added to this page using Markdown and $\\rm \\LaTeX$ math code.\n","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"96344c08df50a1b693cc40432115cbe3","permalink":"/talk/example/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example/","section":"talk","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam.","tags":[],"title":"Example Talk","type":"talk"},{"authors":["GA Cushen"],"categories":null,"content":"More detail can easily be written here using Markdown and $\\rm \\LaTeX$ math code.\n","date":1441065600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1441065600,"objectID":"d77fa4a74076ffcd7ca6c21cfc27a4b2","permalink":"/publication/person-re-id/","publishdate":"2015-09-01T00:00:00Z","relpermalink":"/publication/person-re-id/","section":"publication","summary":"Person re-identification is a critical security task for recognizing a person across spatially disjoint sensors. Previous work can be computationally intensive and is mainly based on low-level cues extracted from RGB data and implemented on a PC for a fixed sensor network (such as traditional CCTV). We present a practical and efficient framework for mobile devices (such as smart phones and robots) where high-level semantic soft biometrics are extracted from RGB and depth data. By combining these cues, our approach attempts to provide robustness to noise, illumination, and minor variations in clothing. This mobile approach may be particularly useful for the identification of persons in areas ill-served by fixed sensors or for tasks where the sensor position and direction need to dynamically adapt to a target. Results on the BIWI dataset are preliminary but encouraging. Further evaluation and demonstration of the system will be available on our website.","tags":[],"title":"A Person Re-Identification System For Mobile Devices","type":"publication"},{"authors":["GA Cushen","MS Nixon"],"categories":null,"content":"More detail can easily be written here using Markdown and $\\rm \\LaTeX$ math code.\n","date":1372636800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1372636800,"objectID":"2b4d919e3cf73dfcd0063c88fe01cb00","permalink":"/publication/clothing-search/","publishdate":"2013-07-01T00:00:00Z","relpermalink":"/publication/clothing-search/","section":"publication","summary":"We present a mobile visual clothing search system whereby a smart phone user can either choose a social networking photo or take a new photo of a person wearing clothing of interest and search for similar clothing in a retail database. From the query image, the person is detected, clothing is segmented, and clothing features are extracted and quantized. The information is sent from the phone client to a server, where the feature vector of the query image is used to retrieve similar clothing products from online databases. The phone's GPS location is used to re-rank results by retail store location. State of the art work focuses primarily on the recognition of a diverse range of clothing offline and pays little attention to practical applications. Evaluated on a challenging dataset, the system is relatively fast and achieves promising results.","tags":[],"title":"Mobile visual clothing search","type":"publication"},{"authors":null,"categories":null,"content":" Welcome to Slides Academic\nFeatures  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides  Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E  Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)  Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = \\;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  Two  Three \nA fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears  Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view   Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links   night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links  Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/img/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}  Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }  Questions? Ask\nDocumentation\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"c2915ec5da95791851caafdcba9664af","permalink":"/slides/example-slides/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/slides/example-slides/","section":"slides","summary":"Welcome to Slides Academic\nFeatures  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides  Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E  Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)  Math In-line math: $x + y = z$","tags":null,"title":"Slides","type":"slides"}]